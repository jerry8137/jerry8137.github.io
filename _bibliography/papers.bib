---
---
@ARTICLE{11143541,
  author={Hou, Chun-Yu and Wang, Chieh-Chih and Lin, Wen-Chieh},
  journal={IEEE Transactions on Radar Systems}, 
  title={Improving Height Estimation for Stationary Targets With 3-D Automotive Radar: From Uncertainty Analysis to Temporal Filtering}, 
  year={2025},
  volume={3},
  number={},
  pages={1195-1206},
  keywords={Radar;Doppler radar;Doppler effect;Three-dimensional displays;Accuracy;Estimation;Automotive engineering;Uncertainty;Radar measurements;Filtering;3-D automotive radar;3-D reconstruction;Advanced Driver Assistance Systems (ADAS);autonomous driving;radar perception},
  abbr={IEEE TRS},
  preview={trs.png},
  selected={true},
  doi={10.1109/TRS.2025.3603807}}


@INPROCEEDINGS{radar_reconstruct,
  author={Hou, Chun-Yu and Wang, Chieh-Chih and Lin, Wen-Chieh},
  booktitle={2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 
  title={Automotive Radar Missing Dimension Reconstruction from Motion}, 
  year={2023},
  volume={},
  number={},
  pages={11226-11232},
  selected={true},
  preview={radar_missing_dim_demo.gif},
  video={https://youtu.be/ExOiUv1MEeY},
  abbr={IROS},
  paper={https://doi.org/10.1109/IROS55552.2023.10342167},
  poster={IROS2023_Poster_Jerry_compressed.pdf},
  abstract={Automotive radars have been reliably used in most assisted and autonomous driving systems due to their robustness to extreme weather conditions. With radial velocity measurements from automotive radars, moving targets such as cars, trucks, and buses can be tracked robustly. However, due to the lack of elevation angles in measurements from automotive radars, stationary targets at different heights, such as maintenance holes and bridges, cannot be distinguished. Most autonomous systems rely on sensor fusion or ignore stationary targets to tackle the problem of missing the elevation angle dimension, which derives safety issues. We propose a simple yet effective approach to estimate the elevation angles of stationary targets from relative velocity and radial velocity measurements from an automotive radar. In contrast to structure from motion in computer vision, we utilize the instantaneous velocity generated from the motion of the ego vehicle. The radial velocity of each target is the projection of relative velocity onto the radial direction from radar to target. The radial velocity of each target can be inferred given the target's azimuth, elevation angle, and relative velocity. Accordingly, the elevation angle of each stationary target can be uniquely calculated given the velocity of radar and the target's azimuth and radial velocity measurements. The radar's velocity is estimated with the existing radar odometry algorithm and IMU. The proposed method is verified with real-world data. We evaluate the system's performance with a pre-built point cloud map and a good localization module in a real-world scenario. The proposed elevation angle reconstruction can reach a 1.41-degree mean error and standard deviation of 0.6 degrees in elevation angle.},
  keywords={},
  doi={10.1109/IROS55552.2023.10342167},
  ISSN={2153-0866},
  month={Oct},}


@ARTICLE{10246160,
  author={Lee, Chia-Le and Hou, Chun-Yu and Wang, Chieh-Chih and Lin, Wen-Chieh},
  journal={IEEE Open Journal of Intelligent Transportation Systems}, 
  title={Extrinsic and Temporal Calibration of Automotive Radar and 3-D LiDAR in Factory and On-Road Calibration Settings}, 
  year={2023},
  volume={4},
  number={},
  pages={708-719},
  paper={https://doi.org/10.1109/OJITS.2023.3312660},
  abbr={IEEE OJITS},
  abstract={While automotive radars are widely used in ADAS and autonomous driving, extrinsic and temporal calibration of automotive radars with other sensors is still daunting due to the sparsity, uncertainty, and missing elevation angles of automotive radar measurements. We propose a target-based calibration approach of 3D automotive radar and 3D LiDAR that performs extrinsic and temporal calibration in both factory and on-road settings. In factory calibration settings, a map is built with precise target poses; target trajectories are estimated based on map-based target localization in which the accuracy of both nearby and faraway target pose estimates can be ensured. The spatial and temporal relationships between radar and LiDAR measurements are established with target trajectories to accomplish extrinsic and temporal calibration. The proposed data collection procedure provides sufficient motion for analyzing time delay between sensors and can significantly reduce the data collection effort and time. There is 52.3% distance error reduction after time delay compensation in the experiment, which shows the improvements of temporal calibration. In on-road calibration settings, the metal objects with semantic labels, such as traffic signs, are selected as calibration targets. Although there could be insufficient correspondences to infer the missing dimension of planar radar for six DoF extrinsic calibration as demonstrated in factory calibration settings, the three extrinsic parameters and the time delay are shown still to be accurate. We validated the proposed method using the nuScenes datasets, which provide sensor measurements, poses, and HD map. With twenty-two data logs, each has over 1000 correspondences, the result of extrinsic parameters reaches centimeter-level accuracy compared with the offered benchmark. The time delay compensation improves 1 meter error for radar tracking in a 20 m/s vehicle case and improves mapping quality in real world data.},
  keywords={},
  doi={10.1109/OJITS.2023.3312660},
  ISSN={2687-7813},
  selected={true},
  month={},
  preview={calibration.png}}
